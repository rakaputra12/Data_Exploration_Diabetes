{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Exploration Projet: Vorhersage von Diabetes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Bevor das Projekt ausgeführt werden muss, muss eine virtuelle Umgebung erstellt und aktiviert werden.\n",
        "\n",
        "\n",
        "1. Um eine virtuelle Umgebung zu erstellen, kann folgender Befehl in Terminal ausgeführt werden:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "python3 -m venv .venv_dep"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. Daher wird ein neuer Ordner in dem Verzeichnis automatisch erstellt.\n",
        "\n",
        "3. Als Nächstes muss die Umgebung mit folgendem Befehl aktiviert werden:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "source .venv_dep/bin/activate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "oder in VSCode muss man manuell die Kernel auf oben rechte Seite festlegen.\n",
        "\n",
        "4. Jetzt ist alles vorbereitet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1711906219284
        },
        "id": "WguKzgM7G7d_"
      },
      "outputs": [],
      "source": [
        "# Install Dependencies\n",
        "\n",
        "%pip install pandas\n",
        "%pip install numpy\n",
        "%pip install scikit-learn\n",
        "%pip install matplotlib\n",
        "%pip install mlflow\n",
        "%pip install seaborn\n",
        "%pip install mlxtend\n",
        "%pip install graphviz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1711906221422
        },
        "id": "aRlvgAd_unKi"
      },
      "outputs": [],
      "source": [
        "#Import Libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "import matplotlib.pyplot as plt\n",
        "from mlxtend.plotting import plot_decision_regions\n",
        "\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTE2ZLv_Ldhf"
      },
      "source": [
        "# **Auswahl Datensatz**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1711906221529
        },
        "id": "NG3V2w_jMaJp"
      },
      "outputs": [],
      "source": [
        "#Import Dataset\n",
        "dataset = \"https://raw.githubusercontent.com/rakaputra12/Data_Exploration_Diabetes/main/Healthcare-Diabetes.csv\"\n",
        "diabetes_df = pd.read_csv(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Der Datensatz ist in dem GitHub-Repository abgelegt, was bedeutet, dass er von überall aus einfach zugänglich ist. Dazu wird auch der Datensatz in dem Ordner dazu gegeben, aber muss die Pfad angepasst werden."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "gather": {
          "logged": 1711906222304
        },
        "id": "Xdlm6-Fputcv",
        "outputId": "1746bbe6-2143-4122-8d97-0ff798d418bd"
      },
      "outputs": [],
      "source": [
        "diabetes_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1711906223280
        },
        "id": "pczFMs0LuxuA"
      },
      "outputs": [],
      "source": [
        "#Delete the column \"Id\"\n",
        "diabetes_df = diabetes_df.drop('Id', axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5x74ba9hLmzL"
      },
      "source": [
        "# **Charakterisierung des Datensatzes**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "gather": {
          "logged": 1711906224331
        },
        "id": "7qekAqg4Ma0A",
        "outputId": "6c5562e1-2d44-4071-e011-43b14a9c52b7"
      },
      "outputs": [],
      "source": [
        "diabetes_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "gather": {
          "logged": 1711906225293
        },
        "id": "61gAIPDau4uW",
        "outputId": "7ac6c7ed-0c5a-49ab-eb57-f59042c7d90e"
      },
      "outputs": [],
      "source": [
        "diabetes_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "gather": {
          "logged": 1711906226497
        },
        "id": "kd-1xQsFu7o7",
        "outputId": "d1b3c6a4-826d-407e-f6f5-bf24a64acb33"
      },
      "outputs": [],
      "source": [
        "diabetes_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "gather": {
          "logged": 1711906227331
        },
        "id": "BEnh52_6vEDh",
        "outputId": "f0f5f7bd-5e0a-4870-cc57-a91248e73863"
      },
      "outputs": [],
      "source": [
        "diabetes_df.describe().T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "gather": {
          "logged": 1711906228435
        },
        "id": "Pssua-XlvEdR",
        "outputId": "a7f05593-da72-4568-92a1-ccc3533e2dfe"
      },
      "outputs": [],
      "source": [
        "diabetes_df.isnull()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "gather": {
          "logged": 1711906229371
        },
        "id": "wsXmozhIvEpB",
        "outputId": "a29052d6-4875-4699-901a-e3c14f94f52d"
      },
      "outputs": [],
      "source": [
        "diabetes_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Im Rohdatensatz, bevor eine Bereinigung durchgeführt wird, ist es nicht ungewöhnlich, fehlende Werte zu finden.Daher ist es in dem Fall wichtig, eine gründliche Untersuchung der fehlenden Werte durchzuführen, um ihr Ausmaß und ihre Verteilung zu verstehen. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "zero_counts = (diabetes_df == 0).sum()\n",
        "zero_counts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-Gug8GLv8Y9"
      },
      "source": [
        "After further checking, it was found that in certain columns, the zero values did not make sense, indicating missing values.\n",
        "\n",
        "Following columns or variables have an invalid zero value: Glucose, BloodPressure, SkinThickness, Insulin, BMI. There are many approachs to handling missing values in a dataset. Replacing zero values with NaN and then filling them with the distribution for each column is one of many common possibilities.\n",
        "\n",
        "Replacing zero values with NaN and then filling them with the distribution for each column is a reasonable approach to handling missing data in this case, cause Reducing the potential bias introduced by using a single imputation method for all missing values leads to more accurate and robust analyses, particularly in datasets where different columns have distinct distributions.This technique allows you to preserve the integrity of the data and capture the uncertainty associated with missing values. On the column like Pregnancies, a value of zero does make sense, cause someone can have never been pregnant. For the column \"Outcome\" is because the value for sufferer or not is only differentiated by one or zero."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Bei einer weiteren Überprüfung wurde festgestellt, dass in bestimmten Spalten die Nullwerte keinen Sinn ergaben, was auf fehlende Werte hindeutet.\n",
        "Die folgenden Spalten oder Variablen haben einen ungültigen Nullwert: Glukose, Blutdruck, Hautdicke, Insulin, BMI. Es gibt viele Ansätze für die Behandlung fehlender Werte in einem Datensatz. Das Ersetzen von Nullwerten durch NaN und das anschließende Auffüllen mit der Verteilung für jede Spalte ist eine von vielen gängigen Möglichkeiten.\n",
        "Das Ersetzen von Nullwerten durch NaN und das anschließende Auffüllen mit der Verteilung für jede Spalte ist in diesem Fall ein vernünftiger Ansatz für den Umgang mit fehlenden Daten, denn die Verringerung der potenziellen Verzerrung durch die Verwendung einer einzigen Imputationsmethode für alle fehlenden Werte führt zu genaueren und robusteren Analysen, insbesondere in Datensätzen, in denen verschiedene Spalten unterschiedliche Verteilungen aufweisen. In der Spalte \"Schwangerschaften\" macht ein Wert von Null durchaus Sinn, da jemand nie schwanger gewesen sein kann. Bei der Spalte \"Ergebnis\" wird der Wert für \"erkrankt\" oder \"nicht erkrankt\" nur durch eins oder null unterschieden."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Replace zeros with NaN Value\n",
        "filtered_diabetes_df = diabetes_df.copy(deep = True)\n",
        "filtered_diabetes_df[['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']] = filtered_diabetes_df[['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']].replace(0,np.NaN)\n",
        "\n",
        "#Showing the Count of NaNs\n",
        "print(filtered_diabetes_df.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Aiming to impute NaN values for the columns in accordance with their distribution\n",
        "fill_values = {\n",
        "    'Glucose': filtered_diabetes_df['Glucose'].mean(),\n",
        "    'BloodPressure': filtered_diabetes_df['BloodPressure'].mean(),\n",
        "    'SkinThickness': filtered_diabetes_df['SkinThickness'].mean(),\n",
        "    'Insulin': filtered_diabetes_df['Insulin'].mean(),\n",
        "    'BMI': filtered_diabetes_df['BMI'].mean()\n",
        "}\n",
        "filtered_diabetes_df.fillna(value=fill_values, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Showing the Count of NaNs\n",
        "print(filtered_diabetes_df.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSLsEglLxXxF"
      },
      "source": [
        "Nun ist der Datensatz bereit zu verarbeiten."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0F4XO9Y0xz6I"
      },
      "source": [
        "## **Perform EDA (Exploratory Data Analysis )**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "gather": {
          "logged": 1711906234676
        },
        "id": "A5QHxqFDx716",
        "outputId": "08d84a81-e9b0-426f-f16c-e352a8d2b4ab"
      },
      "outputs": [],
      "source": [
        "#Checking the balance of the data by plotting the count of outcomes by their values\n",
        "colors = ['#0392cf', '#7bc043']\n",
        "\n",
        "print(filtered_diabetes_df.Outcome.value_counts())\n",
        "p = filtered_diabetes_df.Outcome.value_counts().plot(kind=\"bar\", color = colors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "_KypXfs0mzdD",
        "outputId": "68969a8b-0e0e-4f28-8123-b1982479f466"
      },
      "outputs": [],
      "source": [
        "# Plotting a pie chart to visualize the percentage distribution of diabetes and non-diabetes outcomes\n",
        "filtered_diabetes_df['Outcome'].value_counts().plot(kind='pie',autopct='%1.1f%%')\n",
        "plt.title('Prozentualer Anteil von Diabetes gegenüber Nicht-Diabetes')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0iij8XayE73"
      },
      "source": [
        "The above graph shows that the data is biased towards datapoints having outcome value as 0 where it means that diabetes was not present actually. The number of non-diabetics is almost twice the number of diabetic patients."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Das obige Diagramm zeigt, dass die Daten leicht in Richtung der Datenpunkte mit einem Rückgabewert von 0 verzerrt sind. Die Zahl der Nicht-Diabetiker ist fast doppelt so hoch wie die Zahl der Diabetiker."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "gather": {
          "logged": 1711906292747
        },
        "id": "JYGgv-IBylcY",
        "outputId": "78862408-52a2-4d71-f8b6-70cf7130edf3"
      },
      "outputs": [],
      "source": [
        "#Plotting the Pair Plots for the cleaned data\n",
        "p = sns.pairplot(filtered_diabetes_df, hue= 'Outcome')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Plotting the distribution after replacing the NaN Values\n",
        "p = filtered_diabetes_df.hist(figsize=(15,15))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVjUIcKSy7rW"
      },
      "source": [
        "## **Correlation between all the features**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "rUVojnBknxan",
        "outputId": "60642c18-1f6e-480c-b180-b0e5b0f9e07b"
      },
      "outputs": [],
      "source": [
        "# Calculate the correlation matrix \n",
        "filtered_diabetes_df.corr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "gather": {
          "logged": 1711906293597
        },
        "id": "MD_jmWmKy_6b",
        "outputId": "91205d7a-fec0-475b-ef0a-773a87cb8caf"
      },
      "outputs": [],
      "source": [
        "#Correlation between all the features after cleaning\n",
        "plt.figure(figsize= (12,10))\n",
        "p = sns.heatmap(filtered_diabetes_df.corr(), annot = True, cmap = 'RdYlGn')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7gvffOILrQF"
      },
      "source": [
        "# **Feature Engineering**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1711906293929
        },
        "id": "fgaH6NVuMbkm"
      },
      "outputs": [],
      "source": [
        "#Import Libraries for Feature Enginnering\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1711906294228
        },
        "id": "7YRJoryINvCT"
      },
      "outputs": [],
      "source": [
        "# Extracting features (X) and target variable (y) from the DataFrames\n",
        "X=filtered_diabetes_df[filtered_diabetes_df.columns[0:-1]]\n",
        "y=filtered_diabetes_df[filtered_diabetes_df.columns[-1]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqgjMdgeNdDy"
      },
      "source": [
        "### **Split the dataset for Feature Importance**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1711906294493
        },
        "id": "LGtHE73-NX-H"
      },
      "outputs": [],
      "source": [
        "# Splitting the dataset into training and testing sets\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,stratify=y,random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fsXFCj1SXXS"
      },
      "source": [
        "## **Ermittlung der Feature Importance mit einem Decision Tree**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "gather": {
          "logged": 1711906294799
        },
        "id": "Zzgw_dKrSfTu",
        "outputId": "1fcf0daa-903a-4b2e-d49c-6c60349f01ea"
      },
      "outputs": [],
      "source": [
        "# Instantiate a DecisionTreeClassifier with specified parameters\n",
        "tree = DecisionTreeClassifier(max_depth=4,random_state=0)\n",
        "\n",
        "# Train the Decision Tree classifier on the training data\n",
        "tree.fit(X_train,y_train)\n",
        "\n",
        "# Print the accuracy on the test set and the training set\n",
        "print(\"Accuracy on training set: {:.3f}\".format(tree.score(X_train,y_train)))\n",
        "print(\"Accuracy on test set: {:.3f}\".format(tree.score(X_test,y_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "gather": {
          "logged": 1711906295095
        },
        "id": "3INXxH7VQVif",
        "outputId": "43392122-a7a6-44f8-d60d-8498568d65d7"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import export_graphviz\n",
        "\n",
        "# Export the decision tree visualization to a .dot file\n",
        "export_graphviz(tree,\n",
        "                out_file=\"diabetes_tree.dot\",\n",
        "                class_names=[\"0\",\"1\"],\n",
        "                feature_names=X.columns,\n",
        "                impurity=False,\n",
        "                filled=True)\n",
        "\n",
        "import graphviz\n",
        "\n",
        "# Read the .dot file and visualize the decision tree\n",
        "with open(\"diabetes_tree.dot\") as f:\n",
        "    dot_graph = f.read()\n",
        "graphviz.Source(dot_graph)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "gather": {
          "logged": 1711906295361
        },
        "id": "ZAfJUtfhQjXE",
        "outputId": "28a1f9dd-18c2-4713-f51e-88a9e942962b"
      },
      "outputs": [],
      "source": [
        "print(\"Feature importances:\\n{}\".format(tree.feature_importances_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "gather": {
          "logged": 1711906295750
        },
        "id": "HmUpNotSQvPY",
        "outputId": "1df2c5b3-e3ea-4c7c-df23-085d36b3274f"
      },
      "outputs": [],
      "source": [
        "# Create a DataFrame to display feature importances\n",
        "df_feature_importance = pd.DataFrame({'Feature Names': X.columns, 'Importance of  Feature': tree.feature_importances_ })\n",
        "df_feature_importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "gather": {
          "logged": 1711906296204
        },
        "id": "dj_R-SwTRa7t",
        "outputId": "a45e2492-57df-4de9-ed5e-f6dca396b444"
      },
      "outputs": [],
      "source": [
        "# Plot feature importances using the provided decision tree model\n",
        "def plot_feature_importances_with_DecisionTree(model):\n",
        "    n_features = X.shape[1]\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.barh(range(n_features),model.feature_importances_,align='center')\n",
        "    plt.yticks(np.arange(n_features),X.columns)\n",
        "    plt.xlabel(\"Feature Importance\")\n",
        "    plt.ylabel(\"Feature\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"feature_importance_with_DecisionTree.png\", dpi=300)\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "plot_feature_importances_with_DecisionTree(tree)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEuj71W1R55P"
      },
      "source": [
        "Hier kann man erkennen, dass Feature \"Glucose\", \"BMI\" and \"Age\" Parameter sind, auf die geachtet werden müssen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsOcwWZ_SpuX"
      },
      "source": [
        "## **Ermittlung der Feature Importance mit einem Random  (Als Vergleich)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "gather": {
          "logged": 1711906296401
        },
        "id": "VHOB5TtaSqor",
        "outputId": "956163a1-be02-4898-d3bf-2b3045b82815"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Define feature names\n",
        "feature_names = [f\"feature {i}\" for i in range(X.shape[1])]\n",
        "\n",
        "# Instantiate a RandomForestClassifier with specified parameters\n",
        "forest = RandomForestClassifier(n_estimators=100,random_state=0)\n",
        "\n",
        "# Train the Random Forest classifier on the training data\n",
        "forest.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "gather": {
          "logged": 1711906296745
        },
        "id": "d4f8I4apSzdl",
        "outputId": "7d6440cf-7b77-4b45-faa0-ffd6d96167c5"
      },
      "outputs": [],
      "source": [
        "print(forest.feature_importances_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "gather": {
          "logged": 1711906297175
        },
        "id": "5MvgXphsVL35",
        "outputId": "a11bf855-8347-4ef7-fda4-8d6ad7518bfa"
      },
      "outputs": [],
      "source": [
        "# Create a DataFrame to display feature importances\n",
        "df_feature_importance_withRandomForest = pd.DataFrame({'Feature Names': X.columns, 'Importance of  Feature': forest.feature_importances_ })\n",
        "df_feature_importance_withRandomForest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "gather": {
          "logged": 1711906297340
        },
        "id": "2vokx48dTrdh",
        "outputId": "ff59428a-5577-4f57-91fb-9e7faf8123b2"
      },
      "outputs": [],
      "source": [
        "def plot_feature_importances_with_RandomForest(model):\n",
        "    n_features = X.shape[1]\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.barh(range(n_features),model.feature_importances_,align='center')\n",
        "    plt.yticks(np.arange(n_features),X.columns)\n",
        "    plt.xlabel(\"Feature Importance\")\n",
        "    plt.ylabel(\"Feature\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"feature_imporatnace_with_RandomForest.png\", dpi=300)\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "plot_feature_importances_with_RandomForest(forest)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nach einem Vergleich mit dem RandomForest-Algorithmus wurde bestätigt, dass die Merkmale \"Glucose\", \"BMI\" und \"Age\" als die wichtigsten Merkmale identifiziert wurden. Dies deutet darauf hin, dass diese spezifischen Merkmale einen signifikanten Einfluss auf das Modell haben und einen wesentlichen Beitrag zur Vorhersageleistung leisten. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqW0TVi9Lus2"
      },
      "source": [
        "# **Auswahl der Metriken**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Für den Datensatz \"Diabetes\" wurde dazu entschieden, den F1-Score als Evaluationsmetrik zu verwenden. Der F1-Score ist eine Metrik, die das Gleichgewicht zwischen Präzision und Rückruf (Recall) misst. Es ist besonders nützlich, wenn die Klassen im Datensatz nicht gleichmäßig verteilt sind oder wenn False Positives und False Negatives ähnlich schwerwiegend sind. Im Falle des Diabetes-Datensatzes, bei dem es um die korrekte Vorhersage von Diabetesfällen geht, kann der F1-Score hilfreich sein, um sicherzustellen, dass sowohl die Präzision als auch der Rückruf bei der Vorhersage von positiven Fällen berücksichtigt werden.\n",
        "\n",
        "Es gibt verschiedene Überlegungen und Prioritäten für jede Metrik bei F1-Score:\n",
        "\n",
        "- Micro F1-Score:\n",
        "\n",
        "    - Der Micro F1-Score aggregiert die True Positives, False Positives und False Negatives über alle Klassen und berechnet dann den F1-Score.\n",
        "    - Da er die globale Anzahl der Vorhersagen für jede Klasse berücksichtigt, ist er geeignet, wenn die Klassen unterschiedlich groß sind.\n",
        "    - Dies könnte nützlich sein, wenn es sichergestellt wird, dass das Modell gut auf die insgesamt am häufigsten auftretende Klasse (normalerweise die negative Klasse) reagiert.\n",
        "\n",
        "- Weighted F1-Score:\n",
        "\n",
        "    - Der Weighted F1-Score berücksichtigt die Ungleichheit der Klassen, indem er den F1-Score für jede Klasse berechnet und dann einen gewichteten Durchschnitt basierend auf der Klassegröße nimmt.\n",
        "    - Da er die Klassen entsprechend ihrer Häufigkeit im Datensatz gewichtet, ist er gut geeignet, wenn die Klassen im Datensatz ungleich verteilt sind.\n",
        "    - Dies könnte relevant sein, wenn gleiche Leistung für beide Klassen gewünscht werden oder wenn die positive Klasse (Diabetes positiv) wichtiger ist und es sichergestellt werden möchte, dass das Modell gute Ergebnisse für diese Klasse liefert.\n",
        "\n",
        "\n",
        "In dem Fall wird die Metrik \"Weighted F1-Score\" angewendet, weil hinsichtlich der Charakterisierung des Datensatz die Klasse ungleicht verteilt sind und die Klasse größenteils für negative Klassen sind, daher müssen positive Klassen vorangetrieben und sind wichtiger. Dazu wird Macro F1-Score nicht berücksichtigt, weil er eine gutel Wahl, wenn alle Klasse gleich sind.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6V92ejtL4Tw"
      },
      "source": [
        "# **Auswahl und Beschreibung der ML-Methode**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Dazu kommt die Methode \"Supervised Learning\" zum Einsatz. Dafür wurde auch der Support Vector Machine (SVM) Algorithmus in Betracht gezogen. \n",
        "\n",
        "Die Support Vector Machine ist ein leistungsstarker Algorithmus für die Klassifizierung und Regression, der besonders effektiv in der Verarbeitung komplexer Daten und in Szenarien mit hoher Dimensionalität ist. Dies macht sie zu einer attraktiven Wahl für den Diabetes-Datensatz, der oft Merkmale mit hoher Dimensionalität aufweist und möglicherweise nicht-linear trennbar ist.\n",
        "\n",
        "Ein weiterer Vorteil der SVM ist ihre Fähigkeit, gut mit kleineren Trainingsdatensätzen umzugehen, ohne an Leistung zu verlieren. Dies ist besonders relevant in Situationen, in denen der Diabetes-Datensatz begrenzte Datenpunkte aufweisen könnte.\n",
        "\n",
        "Darüber hinaus bietet die SVM die Möglichkeit, verschiedene Kernel-Funktionen zu verwenden, um die Entscheidungsgrenze zwischen den Klassen anzupassen. Dies ermöglicht es, auch in komplexen, nicht-linearen Datenstrukturen effektive Trennungen zu finden."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jI185bcWqT1J"
      },
      "source": [
        "## **Preparation Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xrr_nfHTlsq0"
      },
      "source": [
        "Bevor das Modell mit Diabetes Datensatz trainiert wird, muss der Datensatz noch ein bisschen vorbereitet werden. Datenpräparation hilft dabei, sicherzustellen, dass die Eingabedaten in der Produktionsumgebung, in der das Modell eingesetzt wird, in der richtigen Form vorliegen und dass das Modell effizient und effektiv arbeiten kann.\n",
        "\n",
        "Es ist auch wichtig zu merken, dass in dem Fall  alle Features für die Training genommen werden, weil zwei Features sehr zu wenig für die Modelling sind."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1711906298265
        },
        "id": "ZMYVlBf8lw9f"
      },
      "outputs": [],
      "source": [
        "# Separating features (X) and target variable (y) from the DataFrame\n",
        "X = filtered_diabetes_df.drop(\"Outcome\", axis=1)\n",
        "y = filtered_diabetes_df['Outcome']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Hier geht es um die Verteilung von Daten**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Normalize the features using StandardScaler\n",
        "x_normalized = StandardScaler().fit_transform(X)\n",
        "# Convert the normalized features into a DataFrame\n",
        "df_x_normalized = pd.DataFrame(x_normalized, columns=X.columns)\n",
        "\n",
        "# Perform PCA with 2 components\n",
        "x_pca  = PCA(n_components=2).fit_transform(df_x_normalized.values)\n",
        "# Convert the PCA results into a DataFrame\n",
        "df_x_pca = pd.DataFrame(x_pca, columns=range(2))\n",
        "\n",
        "# Combine the PCA results with the target variable 'y'\n",
        "df_pca = pd.concat([df_x_pca, y], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ax_jointplot = sns.jointplot(data=df_pca, x=0, y=1, hue=\"Outcome\", kind=\"hist\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r06C2C1mmpuu"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Transform the features using StandardScaler and create a DataFrame with scaled features\n",
        "X = pd.DataFrame(scaler.fit_transform(X), columns=['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
        "       'BMI', 'DiabetesPedigreeFunction', 'Age'])\n",
        "X.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Split Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1711906298711
        },
        "id": "FfI_X66sl_g6"
      },
      "outputs": [],
      "source": [
        "#Split the dataset with size 0.2\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Split the dataset with size 0.3\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5z1PCwFfL6Xi"
      },
      "source": [
        "# **Implementierung Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_60vQYOAtDht"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFZPa1Po2_0b",
        "outputId": "46f2b914-bb64-4d78-adb0-52ca4e64f96f"
      },
      "outputs": [],
      "source": [
        "from sklearn import svm\n",
        "\n",
        "# Instantiate SVM classifier\n",
        "machine = svm.SVC()\n",
        "\n",
        "# Train the SVM classifier on the training data\n",
        "machine.fit(X_train,y_train)\n",
        "\n",
        "# Predict using the trained SVM classifier\n",
        "y_pred = machine.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "clf_acc = accuracy_score(y_pred, y_test)\n",
        "\n",
        "# Print classification report\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Print accuracy of SVM classifier\n",
        "print(\"Accuracy SVM: {:.2f}%\".format(clf_acc * 100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r48H7iPhL_Ib"
      },
      "source": [
        "# **Hyperparametertuning Verwendung ML Lifecycle Mgt im Code**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Hyperparameter-Tuning ist ein entscheidender Schritt im maschinellen Lernprozess, der darauf abzielt, die Leistung eines Modells weiter zu verbessern, indem die optimalen Werte für die Hyperparameter gefunden werden. Selbst wenn ein Modell bereits eine akzeptable Leistung erzielt hat, wie in dem Fall mit einer Punktzahl von 83,75% von der ersten Implementierung, kann das Tuning der Hyperparameter dazu beitragen, die Leistung weiter zu steigern. \n",
        "\n",
        "In dem Fall kommt auch dazu ein ML Lifecylce Management \"MlFlow\" zum Einsatz. Ein ML Lifecycle Management wird verwendet, um Parameter, Metriken und Ausgabedateien zu protokollieren, wenn der maschinellen Lerncode ausgeführt wird, und um die Ergebnisse später zu visualisieren. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1711906300286
        },
        "id": "w0Sy7FCBuImd"
      },
      "outputs": [],
      "source": [
        "#Install Dependencies\n",
        "\n",
        "%pip install mlflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import mlflow\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9I_QHPTl69Ia",
        "outputId": "439c2ce0-6a9b-4d6d-80e3-a450d168b61f"
      },
      "outputs": [],
      "source": [
        "# Start an MLflow run\n",
        "mlflow.start_run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "SxsikUreFfkp",
        "outputId": "d3e3bb79-d46c-4ec3-f08c-77ac9e40e5d3"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define the hyperparameter grid\n",
        "param_grid = {\n",
        "    'C': [0.1, 1.0, 10.0, 100.0],  # Regularization parameter\n",
        "    'kernel': ['linear', 'rbf','poly', 'sigmoid'],  # Kernel type\n",
        "    'degree': [2, 3, 4],  # Degree of the polynomial kernel\n",
        "    'gamma': ['scale', 'auto'],  # Kernel coefficient for 'rbf', 'poly', and 'sigmoid'\n",
        "    'coef0': [0.0, 0.1, 0.5],  # Independent term in kernel function\n",
        "    'shrinking': [True, False],  # Whether to use the shrinking heuristic\n",
        "    'probability': [True, False],  # Whether to enable probability estimates\n",
        "    'tol': [0.0001, 0.001, 0.01],  # Tolerance for stopping criterion\n",
        "}\n",
        "\n",
        "\n",
        "# Create GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=machine, param_grid=param_grid, n_jobs=6, cv=5, scoring='f1_weighted', refit='f1_weighted')\n",
        "\n",
        "# Fit the grid search to the data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# Log parameters and metrics to MLflow\n",
        "mlflow.log_metric(\"best_score\", grid_search.best_score_)\n",
        "# Log the best parameters as a parameter\n",
        "for key, value in grid_search.best_params_.items():\n",
        "    mlflow.log_param(f\"best_{key}\", value)\n",
        "\n",
        "# Log the trained model\n",
        "mlflow.sklearn.log_model(grid_search.best_estimator_, \"svm_model\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_JXpiw1U6lYK"
      },
      "outputs": [],
      "source": [
        " # End the  MLflow run\n",
        "mlflow.end_run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Launch the MLflow UI\n",
        "!mlflow ui"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Um den nächsten Code auszuführen, muss MLFlow ui zuerst durch manuelles Drücken der Stopp-Taste gestoppt werden."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJiyBqF0ME0c"
      },
      "source": [
        "# **Evaluation und Ergebnisdarstellung** | **Predict and Evaluate**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use the best estimator to predict\n",
        "best_estimator = grid_search.best_estimator_\n",
        "y_pred = best_estimator.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "clf_acc = accuracy_score(y_pred, y_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Accuracy SVM after GridSearchCV: {:.2f}%\".format(clf_acc*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "WENN SPLITTING 0.2\n",
        "\n",
        "Nachdem das Hyperparameter-Tuning durchgeführt wurde, konnte die Punktzahl des Modells von 83,75% auf 94,04% gesteigert werden. \n",
        "\n",
        "WENN SPLITTING 0.3\n",
        "\n",
        "Nachdem das Hyperparameter-Tuning durchgeführt wurde, konnte die Punktzahl des Modells von 84,00% auf 93,62% gesteigert werden.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Diese signifikante Verbesserung der Punktzahl zeigt, wie wichtig es ist, die Hyperparameter eines Modells sorgfältig anzupassen. Durch das Feintuning der Hyperparameter konnte das Modell besser auf die spezifischen Anforderungen des Datensatzes abgestimmt werden, was zu einer verbesserten Leistung bei der Klassifizierung von Diabetesfällen führt.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Create a confusin matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-EF2z1MMHDf"
      },
      "source": [
        "# **Vorhersage-Demo | Testing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pssz-hd4pAhU"
      },
      "source": [
        "Die Vorhersage-Demo mit dem Modell, das optimale Hyperparameter verwendet, bietet einen praxisnahen Einblick in die Leistungsfähigkeit des Modells. Benutzer können in der Demo neue Eingabedaten eingeben, und das Modell wird basierend auf diesen Daten Vorhersagen treffen. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14Pf1slNpD95"
      },
      "outputs": [],
      "source": [
        "# Create a dictionary containing the new data\n",
        "new_data = {\n",
        "      'Pregnancies': [1],\n",
        "      'Glucose': [120],\n",
        "      'BloodPressure': [66],\n",
        "      'SkinThickness': [29],\n",
        "      'Insulin': [49],\n",
        "      'BMI': [47.6],\n",
        "      'DiabetesPedigreeFunction': [0.351],\n",
        "      'Age': [27]\n",
        "\n",
        "}\n",
        "\n",
        "# Create a DataFrame from the dictionary\n",
        "new_data = pd.DataFrame(new_data)\n",
        "new_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVdDpk2eu35Y",
        "outputId": "85d97978-856c-42b8-b220-f17ac50a1219"
      },
      "outputs": [],
      "source": [
        "# Scale the new data using the previously fitted StandardScaler\n",
        "scaled_new_data = pd.DataFrame(scaler.transform(new_data), columns=['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
        "                                                                   'BMI', 'DiabetesPedigreeFunction', 'Age'])\n",
        "\n",
        "# Predict the outcome using the best estimator from GridSearchCV\n",
        "y_pred_testing = best_estimator.predict(scaled_new_data)\n",
        "print(\"New Diagnosis from New Data: \", y_pred_testing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Dummy Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.dummy import DummyClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
        "dummy_clf.fit(X_train, y_train)\n",
        "dummy_pred = dummy_clf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Accuracy (Most Frequent Class Dummy Classifier):\", accuracy_score(y_test, dummy_pred))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
